{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a fine-tuning baseline for Pokemon TCG Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import wandb\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "# Define model\n",
    "MODEL = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL.to(DEVICE)\n",
    "\n",
    "# Define image feature extractor and tokenizer\n",
    "FEATURE_EXTRACTOR = AutoFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "#ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "# Define metrics\n",
    "GOOGLE_BLEU_METRIC = evaluate.load('google_bleu')\n",
    "PERPLEXITY = evaluate.load('perplexity', module_type='metric')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(run):\n",
    "    \"\"\"\n",
    "    Download data from wandb\n",
    "    \"\"\"\n",
    "    \n",
    "    split_data_loc = run.use_artifact('pokemon_cards_split:latest')\n",
    "    table = split_data_loc.get(f\"pokemon_table_1k_data_split_seed_{SEED}\")\n",
    "    return table\n",
    "\n",
    "def get_df(table, is_test=False):\n",
    "    \"\"\"\n",
    "    Get dataframe from wandb table\n",
    "    \"\"\"\n",
    "    dataframe = pd.DataFrame(data=table.data, columns=table.columns)\n",
    "\n",
    "    if is_test:\n",
    "        test_df = dataframe[dataframe.split == 'test']\n",
    "        return test_df\n",
    "\n",
    "    train_val_df = dataframe[dataframe.split != 'test']\n",
    "    return train_val_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pytorch Pokemon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch], dim=0),\n",
    "        'labels': torch.stack([x['labels'] for x in batch], dim=0)\n",
    "    }\n",
    "\n",
    "class PokemonCardsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, images:list, captions: list, config) -> None:\n",
    "\n",
    "        self.images = []\n",
    "        for image in images:\n",
    "            image_ = image.image\n",
    "            if image_.mode != \"RGB\":\n",
    "                image_ = image_.convert(mode=\"RGB\")\n",
    "            self.images.append(image_)\n",
    "\n",
    "        self.captions = captions\n",
    "        self.config = config\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.captions)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image = self.images[index]\n",
    "        caption = self.captions[index]\n",
    "\n",
    "        pixel_values = FEATURE_EXTRACTOR(images=image, return_tensors=\"pt\").pixel_values[0]\n",
    "        tokenized_caption = TOKENIZER.encode(\n",
    "            caption, return_tensors='pt', padding='max_length',\n",
    "            truncation='longest_first',\n",
    "            max_length=self.config.generation_max_length)[0]\n",
    "\n",
    "        output = {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': tokenized_caption\n",
    "            }\n",
    "\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table = wandb.Table(columns=['val_iter', 'pred_text', 'gt_text', 'google_bleu'])\n",
    "VAL_ITER = 0\n",
    "\n",
    "def compute_metrics(eval_obj: EvalPrediction):\n",
    "    global VAL_ITER\n",
    "\n",
    "    pred_ids = eval_obj.predictions\n",
    "    gt_ids = eval_obj.label_ids\n",
    "\n",
    "    pred_texts = TOKENIZER.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    pred_texts = [text.strip() for text in pred_texts]\n",
    "\n",
    "    gt_texts = TOKENIZER.batch_decode(gt_ids, skip_special_tokens=True)\n",
    "    gt_texts = [[text.strip()] for text in gt_texts]\n",
    "\n",
    "    avg_google_bleu = []\n",
    "    for i, (pred_text, gt_text) in enumerate(zip(pred_texts, gt_texts)):\n",
    "        # Compute Google BLEU metric\n",
    "        # print(f\"Prediction {i}: {pred_text}\")\n",
    "        # print(f\"Ground truth {i}: {gt_text}\")\n",
    "\n",
    "        google_bleu_metric = \\\n",
    "            GOOGLE_BLEU_METRIC.compute(predictions=[pred_text], references=[gt_text])\n",
    "\n",
    "        metrics_table.add_data(VAL_ITER,\n",
    "                               pred_text, gt_text[0],\n",
    "                               google_bleu_metric['google_bleu'],\n",
    "                               )\n",
    "\n",
    "        avg_google_bleu.append(google_bleu_metric['google_bleu'])\n",
    "\n",
    "    avg_google_bleu = {'avg_google_bleu': sum(avg_google_bleu)/len(avg_google_bleu)}\n",
    "    VAL_ITER += 1\n",
    "\n",
    "    return avg_google_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    \"\"\"\n",
    "    Training process\n",
    "    \"\"\"\n",
    "\n",
    "    run = wandb.init(project='pokemon-cards', entity=None, job_type=\"training\", name=config.run_name)\n",
    "    wandb_table = download_data(run)\n",
    "    train_val_df = get_df(wandb_table)\n",
    "\n",
    "    train_df = train_val_df[train_val_df.split == 'train']\n",
    "    val_df = train_val_df[train_val_df.split == 'valid']\n",
    "\n",
    "    if 'train_limit' in config:\n",
    "        train_df = train_df.iloc[:config.train_limit, :]\n",
    "    if 'val_limit' in config:\n",
    "        val_df = val_df.iloc[:config.val_limit, :]\n",
    "\n",
    "    train_dataset = PokemonCardsDataset(\n",
    "        train_df.image.values,\n",
    "        train_df.caption.values,\n",
    "        config)\n",
    "\n",
    "    val_dataset = PokemonCardsDataset(\n",
    "        val_df.image.values,\n",
    "        val_df.caption.values,\n",
    "        config)\n",
    "\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        predict_with_generate=config.predict_with_generate,\n",
    "        include_inputs_for_metrics=config.include_inputs_for_metrics,\n",
    "        report_to=config.report_to,\n",
    "        run_name=config.run_name,\n",
    "        evaluation_strategy=config.evaluation_strategy,\n",
    "        save_strategy=config.save_strategy,\n",
    "        per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "        num_train_epochs=config.num_train_epochs,\n",
    "        learning_rate=config.learning_rate,\n",
    "        push_to_hub=config.push_to_hub,\n",
    "        load_best_model_at_end=config.load_best_model_at_end,\n",
    "        seed=config.seed,\n",
    "        output_dir=config.output_dir,\n",
    "        optim=config.optim,\n",
    "        generation_max_length=config.generation_max_length,\n",
    "        generation_num_beams=config.generation_num_beams\n",
    "        )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=MODEL,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=collate_fn,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=FEATURE_EXTRACTOR,\n",
    "        )\n",
    "\n",
    "    train_results = trainer.train()\n",
    "\n",
    "    if config.log_preds:\n",
    "        # Save metrics table to wandb\n",
    "        run.log({'fine_tuning': metrics_table})\n",
    "\n",
    "    # run.log({'final_results': train_results})\n",
    "\n",
    "    run.finish()\n",
    "\n",
    "    return train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Namespace(\n",
    "    predict_with_generate=True,\n",
    "    include_inputs_for_metrics=False,\n",
    "    report_to='wandb',\n",
    "    run_name='fine_tuning',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=1e-4,\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=SEED,\n",
    "    output_dir='baseline-ft-model-output/',\n",
    "    optim='adamw_torch',\n",
    "    generation_max_length=256,\n",
    "    generation_num_beams=1,\n",
    "    log_preds=True,\n",
    "    train_limit=256\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb-course-trrCvNNg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
